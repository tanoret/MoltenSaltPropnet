{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Intel MKL WARNING: Support of Intel(R) Streaming SIMD Extensions 4.2 (Intel(R) SSE4.2) enabled only processors has been deprecated. Intel oneAPI Math Kernel Library 2025.0 will require Intel(R) Advanced Vector Extensions (Intel(R) AVX) instructions.\n",
      "Intel MKL WARNING: Support of Intel(R) Streaming SIMD Extensions 4.2 (Intel(R) SSE4.2) enabled only processors has been deprecated. Intel oneAPI Math Kernel Library 2025.0 will require Intel(R) Advanced Vector Extensions (Intel(R) AVX) instructions.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "87a2ecf7429c42eb83398fcaed66ffe0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(HBox(children=(Dropdown(description='Dataset:', options=('mstdb_janz_processed.csv', 'mstdb_pro…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "▶️ on_load_clicked fired\n",
      "▶️ comp_type changed to compounds\n",
      "🔄 Recomputing Composition column (type=compounds)\n",
      "🔄 update_component_options fired\n",
      "   processor has 19 elements and 34 compounds\n",
      "   → set component_selector.options to ['AlCl3', 'BeCl2', 'BeF2', 'CaCl2', 'CaF2', '…']\n",
      "▶️ on_filter_clicked fired\n",
      "▶️ on_train_clicked fired\n",
      "▶️ on_train_clicked fired\n"
     ]
    }
   ],
   "source": [
    "import os, sys\n",
    "import ipywidgets as widgets\n",
    "from IPython.display import display, clear_output, FileLink\n",
    "import numpy as np\n",
    "import math\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy.interpolate import LinearNDInterpolator\n",
    "import matplotlib.tri as mtri\n",
    "\n",
    "# ─────────────────────────────────────────────────────────────────────────────\n",
    "#  Make local package importable\n",
    "# ─────────────────────────────────────────────────────────────────────────────\n",
    "PROJECT_PATH = os.path.abspath(os.path.join(os.getcwd(), \"..\"))\n",
    "sys.path.insert(0, PROJECT_PATH)\n",
    "\n",
    "from processing_mstdb.processor        import MSTDBProcessor\n",
    "from processing_mstdb.trainer          import AIModelTrainer\n",
    "from processing_mstdb.resnet_trainer   import ResNetMetaTrainer, TARGETS as RESNET_TARGETS, DERIVED_PROPS as RESNET_DERIVED_PROPS\n",
    "from processing_mstdb.kan_trainer      import KANMetaTrainer, TARGETS as KAN_TARGETS, DERIVED_PROPS as KAN_DERIVED_PROPS\n",
    "from processing_mstdb.snn_trainer      import SNNMetaTrainer, TARGETS as SNN_TARGETS, DERIVED_PROPS as SNN_DERIVED_PROPS\n",
    "\n",
    "# ─────────────────────────────────────────────────────────────────────────────\n",
    "#  Discover CSVs in data/\n",
    "# ─────────────────────────────────────────────────────────────────────────────\n",
    "data_dir = os.path.join(PROJECT_PATH, \"data\")\n",
    "csv_files = sorted(f for f in os.listdir(data_dir) if f.endswith(\".csv\"))\n",
    "\n",
    "# ─────────────────────────────────────────────────────────────────────────────\n",
    "#  Helper: derive thermo‐props from coefficient dict at temperature T\n",
    "# ─────────────────────────────────────────────────────────────────────────────\n",
    "R = 8.314\n",
    "def derive_properties(coeffs, T):\n",
    "    out = {}\n",
    "    # Density: ρ = a - b·T (missing a or b → zero)\n",
    "    a_rho = coeffs.get(\"rho_a\", 0.0)\n",
    "    b_rho = coeffs.get(\"rho_b\", 0.0)\n",
    "    out[\"rho\"] = a_rho - b_rho * T\n",
    "\n",
    "    # Viscosity (Arrhenius): μA = a·exp(b/(R·T))\n",
    "    a1 = coeffs.get(\"mu1_a\", 0.0)\n",
    "    b1 = coeffs.get(\"mu1_b\", 0.0)\n",
    "    out[\"muA\"] = a1 * math.exp(b1 / (R * T))\n",
    "\n",
    "    # Thermal conductivity: k = a + b·T\n",
    "    a_k = coeffs.get(\"k_a\", 0.0)\n",
    "    b_k = coeffs.get(\"k_b\", 0.0)\n",
    "    out[\"k\"] = a_k + b_k * T\n",
    "\n",
    "    # Heat capacity: cₚ = a + b·T + c/T²\n",
    "    a_cp = coeffs.get(\"cp_a\", 0.0)\n",
    "    b_cp = coeffs.get(\"cp_b\", 0.0)\n",
    "    c_cp = coeffs.get(\"cp_c\", 0.0)\n",
    "    out[\"cp\"] = a_cp + b_cp * T + c_cp / (T**2)\n",
    "\n",
    "    return out\n",
    "\n",
    "# ─────────────────────────────────────────────────────────────────────────────\n",
    "#  Widget definitions\n",
    "# ─────────────────────────────────────────────────────────────────────────────\n",
    "file_dropdown      = widgets.Dropdown(options=csv_files, description=\"Dataset:\")\n",
    "load_button        = widgets.Button(description=\"Load CSV\", button_style=\"primary\")\n",
    "comp_type          = widgets.ToggleButtons(options=[\"elements\",\"compounds\",\"both\"], description=\"Comp Type:\")\n",
    "component_selector = widgets.SelectMultiple(options=[], description=\"Include:\", rows=6)\n",
    "plot_comp_selector = widgets.SelectMultiple(options=[], description=\"Plot Comps:\", rows=6)\n",
    "\n",
    "embedder_dropdown = widgets.Dropdown(\n",
    "    options=[\n",
    "        (\"None\", \"none\"),\n",
    "        (\"PCA (Principal Component Analysis)\", \"pca\"),\n",
    "        (\"Feature Hashing\", \"feature_hashing\"),\n",
    "        (\"t-SNE (t-distributed Stochastic Neighbor Embedding)\", \"tsne\"),\n",
    "        (\"Low Variance Filter\", \"low_variance\"),\n",
    "        (\"NMF (Non-negative Matrix Factorization)\", \"nmf\"),\n",
    "        (\"SVD (Singular Value Decomposition)\", \"svd\"),\n",
    "    ],\n",
    "    value=\"none\",\n",
    "    description=\"Embedder:\",\n",
    "    layout=widgets.Layout(width=\"350px\")\n",
    ")\n",
    "n_components_slider = widgets.IntSlider(\n",
    "    value=10,\n",
    "    min=1,\n",
    "    max=100,\n",
    "    step=1,\n",
    "    description=\"Components:\",\n",
    "    continuous_update=False\n",
    ")\n",
    "\n",
    "filter_button      = widgets.Button(description=\"Filter\", button_style=\"warning\")\n",
    "export_button      = widgets.Button(description=\"Export Filtered\", button_style=\"info\")\n",
    "\n",
    "model_dropdown = widgets.Dropdown(\n",
    "    options=[\n",
    "        (\"Scikit-Learn Polynomial Regressor\",      \"sklearn\"),\n",
    "        (\"ResNet + Meta-Learning + Physics\",        \"resnet\"),\n",
    "        (\"Kernel-Approximation Network (KAN) + Meta\",\"kan\"),\n",
    "        (\"Spiking Neural Network (SNN) + Meta\",     \"snn\"),\n",
    "    ],\n",
    "    description=\"Model:\",\n",
    "    layout=widgets.Layout(width=\"350px\")\n",
    ")\n",
    "train_button       = widgets.Button(description=\"Train Model\", button_style=\"success\")\n",
    "prediction_inputs  = widgets.VBox()\n",
    "temp_slider        = widgets.FloatSlider(value=900, min=300, max=1500, step=10,\n",
    "                                         description=\"Temp (K):\")\n",
    "predict_button     = widgets.Button(description=\"Predict\", button_style=\"info\")\n",
    "output             = widgets.Output()\n",
    "\n",
    "temp_range = widgets.FloatRangeSlider(\n",
    "    value=(300, 1500), min=300, max=1500, step=10,\n",
    "    description='Temp Range (K):', continuous_update=False\n",
    ")\n",
    "plot_button = widgets.Button(description='Plot Range', button_style='primary')\n",
    "comp_plot_button = widgets.Button(description='Plot vs Composition', button_style='info')\n",
    "\n",
    "\n",
    "# ─────────────────────────────────────────────────────────────────────────────\n",
    "#  Debuggable helper: populate Include‐box\n",
    "# ─────────────────────────────────────────────────────────────────────────────\n",
    "def update_component_options(*_):\n",
    "    print(\"🔄 update_component_options fired\")\n",
    "    try:\n",
    "        elems = processor.predefined_elements\n",
    "        comps = processor.predefined_compounds\n",
    "        print(f\"   processor has {len(elems)} elements and {len(comps)} compounds\")\n",
    "    except NameError:\n",
    "        print(\"   ⚠️ processor not defined yet\")\n",
    "        return\n",
    "\n",
    "    if comp_type.value == \"elements\":\n",
    "        opts = sorted(elems)\n",
    "    elif comp_type.value == \"compounds\":\n",
    "        opts = sorted(comps)\n",
    "    else:\n",
    "        opts = sorted(elems | comps)\n",
    "\n",
    "    component_selector.options = opts\n",
    "    preview = opts[:5] + ([\"…\"] if len(opts)>5 else [])\n",
    "    print(f\"   → set component_selector.options to {preview}\")\n",
    "\n",
    "    plot_comp_selector.options = opts\n",
    "\n",
    "# ─────────────────────────────────────────────────────────────────────────────\n",
    "#  Debuggable callback: Load the selected CSV\n",
    "# ─────────────────────────────────────────────────────────────────────────────\n",
    "def on_load_clicked(_):\n",
    "    print(\"▶️ on_load_clicked fired\")\n",
    "    with output:\n",
    "        clear_output()\n",
    "        fname = os.path.join(data_dir, file_dropdown.value)\n",
    "        p = MSTDBProcessor.from_csv(fname)\n",
    "        globals()[\"processor\"] = p\n",
    "        # reset any previous filter\n",
    "        globals().pop(\"filtered_proc\", None)\n",
    "        print(f\"   ✅ Loaded `{file_dropdown.value}` ({len(p.df)} rows)\")\n",
    "\n",
    "        # Compute Composition\n",
    "        print(f\"🔄 Computing Composition column (type={comp_type.value})\")\n",
    "        processor.df[\"Composition\"] = processor.df.apply(\n",
    "            lambda row: processor.compute_composition(row, composition_type=comp_type.value),\n",
    "            axis=1\n",
    "        )\n",
    "\n",
    "        # repopulate Include‐box\n",
    "        update_component_options()\n",
    "\n",
    "# ─────────────────────────────────────────────────────────────────────────────\n",
    "#  Callback: comp_type change\n",
    "# ─────────────────────────────────────────────────────────────────────────────\n",
    "def on_comp_type_changed(change):\n",
    "    print(f\"▶️ comp_type changed to {comp_type.value}\")\n",
    "    if \"processor\" in globals():\n",
    "        print(f\"🔄 Recomputing Composition column (type={comp_type.value})\")\n",
    "        processor.df[\"Composition\"] = processor.df.apply(\n",
    "            lambda row: processor.compute_composition(row, composition_type=comp_type.value),\n",
    "            axis=1\n",
    "        )\n",
    "    update_component_options()\n",
    "\n",
    "# ─────────────────────────────────────────────────────────────────────────────\n",
    "#  NEW: Filter callback\n",
    "# ─────────────────────────────────────────────────────────────────────────────\n",
    "def on_filter_clicked(_):\n",
    "    print(\"▶️ on_filter_clicked fired\")\n",
    "    with output:\n",
    "        clear_output()\n",
    "        if \"processor\" not in globals():\n",
    "            print(\"⚠️  Load a dataset first.\")\n",
    "            return\n",
    "        if not component_selector.value:\n",
    "            print(\"⚠️  Select at least one element/compound to filter.\")\n",
    "            return\n",
    "\n",
    "        flt = {\"include\": {comp_type.value: list(component_selector.value)}}\n",
    "        fp = processor.filter_by_components(flt)\n",
    "        globals()[\"filtered_proc\"] = fp\n",
    "        plot_comp_selector.options = list(component_selector.value)\n",
    "        print(f\"   ✅ Filter applied: {len(fp.df)} rows remain\")\n",
    "\n",
    "# ─────────────────────────────────────────────────────────────────────────────\n",
    "#  NEW: Export callback\n",
    "# ─────────────────────────────────────────────────────────────────────────────\n",
    "def on_export_clicked(_):\n",
    "    print(\"▶️ on_export_clicked fired\")\n",
    "    with output:\n",
    "        clear_output()\n",
    "        if \"filtered_proc\" not in globals():\n",
    "            print(\"⚠️  Nothing to export. Run **Filter** first.\")\n",
    "            return\n",
    "        out_path = \"filtered_data.csv\"\n",
    "        filtered_proc.df.to_csv(out_path, index=False)\n",
    "        print(f\"   ✅ Exported filtered data to `{out_path}`\")\n",
    "        display(FileLink(out_path))\n",
    "\n",
    "# ─────────────────────────────────────────────────────────────────────────────\n",
    "#  Callback: Train the chosen model on the filtered data\n",
    "# ─────────────────────────────────────────────────────────────────────────────\n",
    "def on_train_clicked(_):\n",
    "    print(\"▶️ on_train_clicked fired\")\n",
    "    with output:\n",
    "        clear_output()\n",
    "\n",
    "        # 1️⃣ Make sure we have a base processor\n",
    "        if \"processor\" not in globals():\n",
    "            print(\"⚠️  Load a dataset first.\")\n",
    "            return\n",
    "\n",
    "        # 2️⃣ Grab the user’s include list\n",
    "        includes = list(component_selector.value)\n",
    "        if not includes:\n",
    "            print(\"⚠️  Select at least one element/compound.\")\n",
    "            return\n",
    "\n",
    "        # 3️⃣ Apply the filter right now (overwrite filtered_proc)\n",
    "        print(f\"🔄 Applying filter: include {comp_type.value} = {includes}\")\n",
    "        flt = {\"include\": {comp_type.value: includes}}\n",
    "        fp = processor.filter_by_components(flt)\n",
    "        globals()[\"filtered_proc\"] = fp\n",
    "        print(f\"   ✅ Filtered down to {len(fp.df)} rows\")\n",
    "\n",
    "        # 4️⃣ Now train on filtered_proc.df\n",
    "        emethod = embedder_dropdown.value\n",
    "        ncomp   = n_components_slider.value\n",
    "        cm = model_dropdown.value\n",
    "        globals()[\"current_model\"] = cm\n",
    "        ds_df = filtered_proc.df\n",
    "\n",
    "        print(f\"🛠 Training {cm} with embedder={emethod}, n_components={ncomp} on {len(ds_df)} samples…\")\n",
    "        if cm == \"sklearn\":\n",
    "            print(emethod)\n",
    "            globals()[\"trainer\"] = AIModelTrainer(ds_df, embedding_method=emethod, embedding_params={\"n_components\": ncomp})\n",
    "            trainer.train_all()\n",
    "        elif cm == \"resnet\":\n",
    "            globals()[\"trainer\"] = ResNetMetaTrainer(\n",
    "                ds_df,\n",
    "                RESNET_TARGETS,\n",
    "                RESNET_DERIVED_PROPS,\n",
    "                embedding_method=emethod,\n",
    "                n_components=ncomp\n",
    "            )\n",
    "            trainer.train_base(); trainer.train_meta(); trainer.train_joint()\n",
    "        elif cm == \"kan\":\n",
    "            globals()[\"trainer\"] = KANMetaTrainer(\n",
    "                ds_df,\n",
    "                RESNET_TARGETS,\n",
    "                RESNET_DERIVED_PROPS,\n",
    "                embedding_method=emethod,\n",
    "                n_components=ncomp\n",
    "            )\n",
    "            trainer.train_base(); trainer.train_meta(); trainer.train_joint()\n",
    "        else:  # snn\n",
    "            globals()[\"trainer\"] = SNNMetaTrainer(\n",
    "                ds_df,\n",
    "                RESNET_TARGETS,\n",
    "                RESNET_DERIVED_PROPS,\n",
    "                embedding_method=emethod,\n",
    "                n_components=ncomp\n",
    "            )\n",
    "            trainer.train_base(); trainer.train_meta(); trainer.train_joint()\n",
    "\n",
    "        print(f\"   ✅ {cm} training complete.\")\n",
    "\n",
    "        # 5️⃣ Rebuild the prediction widgets\n",
    "        prediction_inputs.children = [\n",
    "            widgets.BoundedFloatText(value=0.0, min=0.0, max=1.0, step=0.01, description=c)\n",
    "            for c in includes\n",
    "        ]\n",
    "\n",
    "# ─────────────────────────────────────────────────────────────────────────────\n",
    "#  Callback: Predict either direct properties (sklearn) or coeff→properties\n",
    "# ─────────────────────────────────────────────────────────────────────────────\n",
    "def on_predict_clicked(_):\n",
    "    print(\"▶️ on_predict_clicked fired\")\n",
    "    with output:\n",
    "        clear_output()\n",
    "        if \"trainer\" not in globals():\n",
    "            print(\"⚠️  Train a model first.\")\n",
    "            return\n",
    "\n",
    "        # Build a one‐row DataFrame from the inputs\n",
    "        comp_dict = {w.description: w.value for w in prediction_inputs.children}\n",
    "        print(f\"🔍 Composition dict: {comp_dict}\")\n",
    "        # Align columns to the trainer's composition_df\n",
    "        import pandas as _pd\n",
    "        input_df = _pd.DataFrame([comp_dict])\n",
    "        # fill any missing columns with zero\n",
    "        cols = trainer.composition_df.columns\n",
    "        input_df = input_df.reindex(columns=cols, fill_value=0.0)\n",
    "        print(f\"   → Input columns aligned to {list(cols)}\")\n",
    "\n",
    "        # Apply polynomial expansion\n",
    "        X_poly = trainer.poly.transform(input_df)\n",
    "        print(f\"   → X_poly shape: {X_poly.shape}\")\n",
    "\n",
    "        # Now loop over each target\n",
    "        preds = {}\n",
    "        for target, model in trainer.best_models.items():\n",
    "            scaler = trainer.scalers[target]\n",
    "            X_scaled = scaler.transform(X_poly)\n",
    "            p = model.predict(X_scaled)[0]\n",
    "            # match original logic for densities\n",
    "            if \"a\" in target:\n",
    "                p = max(p, 1e-10)\n",
    "            preds[target] = p\n",
    "            print(f\"   • Raw prediction for {target}: {p:.4e}\")\n",
    "\n",
    "        globals()['last_preds'] = preds\n",
    "        print(\"🔖 Coefficients saved for plotting\")\n",
    "\n",
    "        if current_model == \"sklearn\":\n",
    "            # For sklearn we directly predicted properties\n",
    "            print(\"\\n✅ Predicted Properties:\")\n",
    "            for k, v in preds.items():\n",
    "                print(f\"   {k}: {v:.4f}\")\n",
    "\n",
    "        else:\n",
    "            # For the other networks, preds are fit‐coefficients\n",
    "            print(\"\\n✅ Predicted Fit Coefficients:\")\n",
    "            for k, v in preds.items():\n",
    "                print(f\"   {k}: {v:.4f}\")\n",
    "\n",
    "            # derive actual thermo props at the chosen temperature\n",
    "            T = temp_slider.value\n",
    "            derived = trainer.derived(preds, T)\n",
    "            print(f\"\\n   → Derived properties at {T} K:\")\n",
    "            for k, v in derived.items():\n",
    "                print(f\"     {k}: {v:.4f}\")\n",
    "\n",
    "\n",
    "# ─────────────────────────────────────────────────────────────────────────────\n",
    "#  Callback: Plot predicted properties\n",
    "# ─────────────────────────────────────────────────────────────────────────────\n",
    "def on_plot_clicked(_):\n",
    "    with output:\n",
    "        clear_output()\n",
    "        if \"last_preds\" not in globals():\n",
    "            print(\"⚠️  Please run Predict first.\")\n",
    "            return\n",
    "\n",
    "        coeffs = globals()[\"last_preds\"]\n",
    "        Tmin, Tmax = temp_range.value\n",
    "        Ts = np.linspace(Tmin, Tmax, 50)\n",
    "\n",
    "        # map property keys to nice labels\n",
    "        prop_labels = {\n",
    "            \"rho\": \"Density ρ (kg/m³)\",\n",
    "            \"muA\": \"Viscosity μ (Arrhenius)\",\n",
    "            \"k\":   \"Thermal Conductivity k (W/m·K)\",\n",
    "            \"cp\":  \"Heat Capacity cₚ (J/kg·K)\"\n",
    "        }\n",
    "\n",
    "        # collect curves\n",
    "        curves = {}\n",
    "        for T in Ts:\n",
    "            props = derive_properties(coeffs, T)\n",
    "            for name, val in props.items():\n",
    "                curves.setdefault(name, {\"x\": [], \"y\": []})\n",
    "                curves[name][\"x\"].append(T)\n",
    "                curves[name][\"y\"].append(val)\n",
    "\n",
    "        import matplotlib.pyplot as plt\n",
    "\n",
    "        for name, data in curves.items():\n",
    "            if len(data[\"x\"]) < 2:\n",
    "                continue\n",
    "\n",
    "            # build the equation string\n",
    "            if name == \"rho\":\n",
    "                eq = f\"ρ = {coeffs['rho_a']:.2e} – {coeffs['rho_b']:.2e}·T\"\n",
    "            elif name == \"muA\":\n",
    "                eq = f\"μ = {coeffs['mu1_a']:.2e}·exp({coeffs['mu1_b']:.2e}/(R·T))\"\n",
    "            elif name == \"k\":\n",
    "                eq = f\"k = {coeffs['k_a']:.2e} + {coeffs['k_b']:.2e}·T\"\n",
    "            else:  # cp\n",
    "                eq = (f\"cₚ = {coeffs['cp_a']:.2e} + {coeffs['cp_b']:.2e}·T + \"\n",
    "                      f\"{coeffs['cp_c']:.2e}/T²\")\n",
    "\n",
    "            # publication-quality plot\n",
    "            plt.figure(figsize=(6,4))\n",
    "            plt.plot(data[\"x\"], data[\"y\"], linewidth=2, marker='o', markersize=4)\n",
    "            plt.grid(True, linestyle=\"--\", alpha=0.6)\n",
    "            plt.xlabel(\"Temperature (K)\", fontsize=12)\n",
    "            plt.ylabel(prop_labels.get(name, name), fontsize=12)\n",
    "            if name in (\"muA\"):\n",
    "                plt.yscale(\"log\")\n",
    "            plt.title(f\"{prop_labels.get(name, name)} vs Temperature\", fontsize=14)\n",
    "            plt.legend([eq], fontsize=10, loc=\"best\")\n",
    "            plt.tight_layout()\n",
    "            plt.show()\n",
    "\n",
    "# ─────────────────────────────────────────────────────────────────────────────\n",
    "#  New: Plot vs Composition callback\n",
    "# ─────────────────────────────────────────────────────────────────────────────\n",
    "def on_comp_plot_clicked(_):\n",
    "    print(\"▶️ on_comp_plot_clicked fired\")\n",
    "    with output:\n",
    "        clear_output()\n",
    "        if \"trainer\" not in globals():\n",
    "            print(\"⚠️  Train a model first.\")\n",
    "            return\n",
    "\n",
    "        comps = list(plot_comp_selector.value)\n",
    "        if not comps:\n",
    "            print(\"⚠️  Select at least one component.\")\n",
    "            return\n",
    "\n",
    "        T = temp_slider.value\n",
    "        grid = np.linspace(0,1,50)\n",
    "\n",
    "        import pandas as _pd\n",
    "\n",
    "        def predict_coeffs(comp_dict):\n",
    "            # exactly same feature‐prep as on_predict_clicked\n",
    "            df = _pd.DataFrame([comp_dict])\n",
    "            df = df.reindex(columns=trainer.composition_df.columns, fill_value=0.0)\n",
    "            X_poly = trainer.poly.transform(df)\n",
    "            preds = {}\n",
    "            for target, model in trainer.best_models.items():\n",
    "                scaler = trainer.scalers[target]\n",
    "                Xs = scaler.transform(X_poly)\n",
    "                p = model.predict(Xs)[0]\n",
    "                if \"a\" in target:\n",
    "                    p = max(p, 1e-10)\n",
    "                preds[target] = p\n",
    "            return preds\n",
    "\n",
    "        # single‐component sweep\n",
    "        if len(comps) == 1:\n",
    "            comp = comps[0]\n",
    "            data = {}\n",
    "            for f in grid:\n",
    "                coeffs = predict_coeffs({comp: f})\n",
    "                props  = derive_properties(coeffs, T)\n",
    "                for name, val in props.items():\n",
    "                    data.setdefault(name, []).append(val)\n",
    "\n",
    "            for name, vals in data.items():\n",
    "                plt.figure(figsize=(6,4))\n",
    "                plt.plot(grid, vals, '-o', linewidth=2, markersize=4)\n",
    "                if name in (\"muA\"):\n",
    "                    plt.yscale(\"log\")\n",
    "                plt.xlabel(f\"{comp} Fraction\", fontsize=12)\n",
    "                plt.ylabel(name, fontsize=12)\n",
    "                plt.title(f\"{name} vs {comp} at {T} K\", fontsize=14)\n",
    "                plt.grid(True, linestyle='--', alpha=0.6)\n",
    "                plt.tight_layout()\n",
    "                plt.show()\n",
    "\n",
    "        # binary sweep\n",
    "        elif len(comps) == 2:\n",
    "            c1, c2 = comps\n",
    "            data = {}\n",
    "            for f in grid:\n",
    "                coeffs = predict_coeffs({c1: f, c2: 1-f})\n",
    "                props  = derive_properties(coeffs, T)\n",
    "                for name, val in props.items():\n",
    "                    data.setdefault(name, []).append(val)\n",
    "\n",
    "            for name, vals in data.items():\n",
    "                plt.figure(figsize=(6,4))\n",
    "                plt.plot(grid, vals, '-o', linewidth=2, markersize=4)\n",
    "                if name in (\"muA\"):\n",
    "                    plt.yscale(\"log\")\n",
    "                plt.xlabel(f\"{c1} Fraction\", fontsize=12)\n",
    "                plt.ylabel(name, fontsize=12)\n",
    "                plt.title(f\"{name} over {c1}/{c2} at {T} K\", fontsize=14)\n",
    "                plt.grid(True, linestyle='--', alpha=0.6)\n",
    "                plt.tight_layout()\n",
    "                plt.show()\n",
    "\n",
    "        # ternary sweep (first three comps)\n",
    "        else:\n",
    "            from scipy.interpolate import LinearNDInterpolator\n",
    "            import matplotlib.tri as mtri\n",
    "\n",
    "            labels   = comps[:3]\n",
    "            n_coarse = 20\n",
    "\n",
    "            for name in [\"rho\",\"muA\",\"k\",\"cp\"]:\n",
    "                # 1) build coarse (xs, ys, cs) for this property\n",
    "                xs, ys, cs = [], [], []\n",
    "                for i in range(n_coarse+1):\n",
    "                    for j in range(n_coarse+1-i):\n",
    "                        kf = n_coarse - i - j\n",
    "                        f1, f2, f3 = i/n_coarse, j/n_coarse, kf/n_coarse\n",
    "                        coeffs = predict_coeffs({\n",
    "                            labels[0]: f1,\n",
    "                            labels[1]: f2,\n",
    "                            labels[2]: f3\n",
    "                        })\n",
    "                        props = derive_properties(coeffs, T)\n",
    "                        if name in props:\n",
    "                            xs.append(0.5*(2*f2 + f3))\n",
    "                            ys.append((np.sqrt(3)/2)*f3)\n",
    "                            cs.append(props[name])\n",
    "\n",
    "                if not xs:\n",
    "                    continue\n",
    "\n",
    "                # 2) fit interpolator\n",
    "                pts   = np.vstack((xs, ys)).T\n",
    "                interp = LinearNDInterpolator(pts, cs)\n",
    "\n",
    "                # 3) sample fine grid\n",
    "                n_fine = 100\n",
    "                x_fine, y_fine = [], []\n",
    "                for i in range(n_fine+1):\n",
    "                    for j in range(n_fine+1-i):\n",
    "                        kf = n_fine - i - j\n",
    "                        f1, f2, f3 = i/n_fine, j/n_fine, kf/n_fine\n",
    "                        x = 0.5*(2*f2 + f3)\n",
    "                        y = (np.sqrt(3)/2)*f3\n",
    "                        x_fine.append(x)\n",
    "                        y_fine.append(y)\n",
    "                x_fine = np.array(x_fine)\n",
    "                y_fine = np.array(y_fine)\n",
    "\n",
    "                # 4) evaluate and mask NaNs\n",
    "                z_fine = interp(x_fine, y_fine)\n",
    "                mask   = ~np.isnan(z_fine)\n",
    "                x_f, y_f, z_f = x_fine[mask], y_fine[mask], z_fine[mask]\n",
    "\n",
    "                # 5) triangulate and contour\n",
    "                tri = mtri.Triangulation(x_f, y_f)\n",
    "                plt.figure(figsize=(6,6))\n",
    "\n",
    "                if name in (\"muA\"):\n",
    "                    from matplotlib.colors import LogNorm\n",
    "                    cf = plt.tricontourf(\n",
    "                        tri, z_f,\n",
    "                        levels=20,\n",
    "                        cmap='viridis',\n",
    "                        norm=LogNorm(),\n",
    "                        alpha=0.9\n",
    "                    )\n",
    "                else:\n",
    "                    cf = plt.tricontourf(tri, z_f, levels=20, cmap='viridis', alpha=0.9)\n",
    "\n",
    "                plt.colorbar(cf, label=name, shrink=0.8)\n",
    "\n",
    "                # 6) border & vertex labels\n",
    "                verts_x = [0, 1, 0.5, 0]\n",
    "                verts_y = [0, 0, np.sqrt(3)/2, 0]\n",
    "                plt.plot(verts_x, verts_y, 'k-', lw=1)\n",
    "                plt.text(0, -0.05,  labels[0], ha='center', va='top', fontsize=12)\n",
    "                plt.text(1, -0.05,  labels[1], ha='center', va='top', fontsize=12)\n",
    "                plt.text(0.5, np.sqrt(3)/2+0.03, labels[2], ha='center', va='bottom', fontsize=12)\n",
    "\n",
    "                plt.title(f\"{name} ternary at {T} K\", fontsize=14)\n",
    "                plt.axis('off')\n",
    "                plt.tight_layout()\n",
    "                plt.show()\n",
    "\n",
    "\n",
    "# ─────────────────────────────────────────────────────────────────────────────\n",
    "#  Wire callbacks and display the UI\n",
    "# ─────────────────────────────────────────────────────────────────────────────\n",
    "load_button.on_click(on_load_clicked)\n",
    "comp_type.observe(on_comp_type_changed, names=\"value\")\n",
    "filter_button.on_click(on_filter_clicked)\n",
    "export_button.on_click(on_export_clicked)\n",
    "train_button.on_click(on_train_clicked)\n",
    "predict_button.on_click(on_predict_clicked)\n",
    "plot_button.on_click(on_plot_clicked)\n",
    "comp_plot_button.on_click(on_comp_plot_clicked)\n",
    "\n",
    "ui = widgets.VBox([\n",
    "    widgets.HBox([file_dropdown, load_button]),\n",
    "    widgets.HBox([comp_type, component_selector]),\n",
    "    widgets.HBox([filter_button, export_button]),\n",
    "    widgets.HBox([embedder_dropdown, n_components_slider]),\n",
    "    widgets.HBox([model_dropdown, train_button]),\n",
    "    widgets.Label(\"Prediction Inputs:\"),\n",
    "    prediction_inputs,\n",
    "    temp_slider,\n",
    "    predict_button,\n",
    "    temp_range,\n",
    "    plot_button,\n",
    "    widgets.Label(\"Composition Evolution:\"),\n",
    "    widgets.Label(\"Choose comps for composition‐plot:\"),\n",
    "    plot_comp_selector,\n",
    "    comp_plot_button,\n",
    "    output\n",
    "])\n",
    "\n",
    "display(ui)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "scientific_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
